// === ArrowTableIterator.hpp ===
#pragma once

#include <arrow/api.h>
#include <arrow/record_batch.h>
#include <arrow/flight/api.h>
#include <vector>
#include <memory>
#include <tuple>
#include <string>
#include <type_traits>

// ---- Transformer Framework ----
// Base Transformer CRTP: specialize for ArrowType and UserType
template<typename ArrowType, typename UserType, typename Derived>
struct Transformer {
    using arrow_c_type = typename ArrowType::c_type;
    static constexpr UserType forward(arrow_c_type v) {
        return Derived::forward_impl(v);
    }
    static constexpr arrow_c_type backward(UserType v) {
        return Derived::backward_impl(v);
    }
};

// Identity transformer
template<typename ArrowType>
struct Identity : Transformer<ArrowType, typename ArrowType::c_type, Identity<ArrowType>> {
    static constexpr typename ArrowType::c_type forward_impl(typename ArrowType::c_type v) { return v; }
    static constexpr typename ArrowType::c_type backward_impl(typename ArrowType::c_type v) { return v; }
};

// ReceiveAll transformer: catches any arrow::Scalar
struct ReceiveAllTransformer {
    using UserType = std::shared_ptr<arrow::Scalar>;
    static std::shared_ptr<arrow::Scalar> forward_impl(std::shared_ptr<arrow::Scalar> v) { return v; }
    static std::shared_ptr<arrow::Scalar> backward_impl(std::shared_ptr<arrow::Scalar> v) { return v; }
};

// ---- Transformer List with currying ----
template<typename... Ts>
struct TransformerList {
    template<typename New>
    using append = TransformerList<Ts..., New>;
};

template<typename List, size_t N>
struct TransformerAt;
template<typename Head, typename... Tail>
struct TransformerAt<TransformerList<Head, Tail...>, 0> { using type = Head; };
template<typename Head, typename... Tail, size_t N>
struct TransformerAt<TransformerList<Head, Tail...>, N> : TransformerAt<TransformerList<Tail...>, N-1> {};

// ---- Metadata Checker ----
// Default: allow all rows
template<typename SchemaMetadataKey, typename SchemaMetadataValue>
struct MetadataFilter {
    static bool check(const std::shared_ptr<arrow::Schema>& schema,
                      std::shared_ptr<arrow::RecordBatch>,
                      int64_t) {
        auto md = schema->metadata();
        return md && md->Get(SchemaMetadataKey::value).ValueOr("") == SchemaMetadataValue::value;
    }
};

struct AllowAll {
    static bool check(const std::shared_ptr<arrow::Schema>&, std::shared_ptr<arrow::RecordBatch>, int64_t) {
        return true;
    }
};

// ---- Streamed Backend ----
class StreamedBackend {
public:
    explicit StreamedBackend(std::unique_ptr<arrow::flight::FlightStreamReader> reader)
        : reader_(std::move(reader)) {}
    std::shared_ptr<arrow::RecordBatch> next_batch() {
        auto res = reader_->Next();
        if (res.ok() && res.ValueUnsafe()) return res.ValueUnsafe();
        return nullptr;
    }
    std::shared_ptr<arrow::Schema> schema() const { return reader_->schema(); }
private:
    std::unique_ptr<arrow::flight::FlightStreamReader> reader_;
};

// ---- Row Proxy ----
template<typename Transformers>
class RowProxy {
public:
    RowProxy(std::shared_ptr<arrow::RecordBatch> batch, int64_t row)
        : batch_(batch), row_(row) {}

    // get by index
    template<size_t I>
    auto get() const {
        using TransformerT = typename TransformerAt<Transformers, I>::type;
        using CType = typename TransformerT::arrow_c_type;
        auto array = std::static_pointer_cast<typename arrow::NumericArray<typename CType::TypeClass>>(batch_->column(I));
        return TransformerT::forward(array->Value(row_));
    }
    // catch-all sink
    std::vector<std::shared_ptr<arrow::Scalar>> receive_all() const {
        std::vector<std::shared_ptr<arrow::Scalar>> extras;
        size_t ncol = batch_->num_columns();
        constexpr size_t Tcols = std::tuple_size<Transformers>::value;
        for (size_t i = Tcols; i < ncol; ++i) {
            auto res = batch_->column(i)->GetScalar(row_);
            if (res.ok()) extras.push_back(res.ValueUnsafe());
        }
        return extras;
    }
private:
    std::shared_ptr<arrow::RecordBatch> batch_;
    int64_t row_;
};

// ---- Iterator ----
template<typename Backend, typename Transformers, typename MetaChecker = AllowAll>
class RowIterator {
public:
    using value_type = RowProxy<Transformers>;
    RowIterator(std::shared_ptr<Backend> backend, bool end = false)
        : backend_(backend) {
        if (!end) { advance_batch(); advance_row(); }
        row_idx_ = end ? -1 : row_idx_;
    }
    bool operator!=(RowIterator const& other) const {
        return row_idx_ != other.row_idx_ || batch_.get() != other.batch_.get();
    }
    RowIterator& operator++() { advance_row(); return *this; }
    value_type operator*() const { return {batch_, row_idx_}; }
private:
    void advance_batch() { batch_ = backend_->next_batch(); row_idx_ = 0; }
    void advance_row() {
        while (batch_) {
            if (row_idx_ < batch_->num_rows() && MetaChecker::check(batch_->schema(), batch_, row_idx_)) return;
            if (++row_idx_ >= batch_->num_rows()) advance_batch();
        }
        row_idx_ = -1;
    }
    std::shared_ptr<Backend> backend_;
    std::shared_ptr<arrow::RecordBatch> batch_;
    int64_t row_idx_;
};

// ---- Table View ----
template<typename Backend, typename Transformers, typename MetaChecker = AllowAll>
class TableView {
public:
    explicit TableView(std::shared_ptr<Backend> backend) : backend_(backend) {}
    auto begin() { return RowIterator<Backend, Transformers, MetaChecker>(backend_, false); }
    auto end()   { return RowIterator<Backend, Transformers, MetaChecker>(backend_, true); }
    // currying syntax
    template<typename NewTransformer>
    auto addTransformer() const {
        using NewList = typename Transformers::template append<NewTransformer>;
        return TableView<Backend, NewList, MetaChecker>(backend_);
    }
private:
    std::shared_ptr<Backend> backend_;
};


// === flight_double_roundtrip_client.cpp ===
#include "ArrowTableIterator.hpp"
#include <arrow/api.h>
#include <arrow/flight/api.h>
#include <arrow/record_batch.h>
#include <arrow/table.h>
#include <iostream>

struct ProcessTrueKey { static constexpr const char* value = "process"; };
struct ProcessTrueVal { static constexpr const char* value = "true"; };

int main() {
    auto loc = arrow::flight::Location::ForGrpcTcp("localhost", 8815).ValueOrDie();
    auto client = arrow::flight::FlightClient::Connect(loc).ValueOrDie();
    arrow::flight::FlightDescriptor descr = arrow::flight::FlightDescriptor::Command("my_table");

    // Build and set schema metadata to enable filter
    arrow::KeyValueMetadata metadata;
    metadata.Append("process", "true");
    auto schema = arrow::schema({
        arrow::field("i32", arrow::int32()),
        arrow::field("f64", arrow::float64()),
        arrow::field("bol", arrow::boolean()),
        arrow::field("str", arrow::utf8())
    }, std::make_shared<arrow::KeyValueMetadata>(metadata));

    // Build table
    arrow::Int32Builder b1; b1.AppendValues({1,2,3}); std::shared_ptr<arrow::Array> a1; b1.Finish(&a1);
    arrow::DoubleBuilder b2; b2.AppendValues({0.1,0.2,0.3}); std::shared_ptr<arrow::Array> a2; b2.Finish(&a2);
    arrow::BooleanBuilder b3; b3.AppendValues({true,false,true}); std::shared_ptr<arrow::Array> a3; b3.Finish(&a3);
    arrow::StringBuilder b4; b4.AppendValues({"a","b","c"}); std::shared_ptr<arrow::Array> a4; b4.Finish(&a4);
    auto table1 = arrow::Table::Make(schema, {a1,a2,a3,a4});

    auto do_put = [&](std::shared_ptr<arrow::Table> tbl) {
        auto [writer, _] = client->DoPut(descr, tbl->schema());
        arrow::TableBatchReader reader(*tbl);
        reader.set_chunksize(2);
        std::shared_ptr<arrow::RecordBatch> rb;
        while (reader.ReadNext(&rb).ok() && rb) writer->WriteRecordBatch(*rb);
        writer->Close();
    };

    // First roundtrip
    do_put(table1);
    auto info1 = client->GetFlightInfo(descr).ValueOrDie();
    auto stream1 = client->DoGet(info1.endpoints()[0].ticket).ValueOrDie();
    std::shared_ptr<arrow::Table> table2;
    arrow::Table::FromRecordBatchReader(std::move(stream1), &table2).ValueOrDie();
    std::cout << "After 1st roundtrip:\n" << table2->ToString() << std::endl;

    // Second roundtrip
    do_put(table2);
    auto info2 = client->GetFlightInfo(descr).ValueOrDie();
    auto stream2 = client->DoGet(info2.endpoints()[0].ticket).ValueOrDie();
    auto backend = std::make_shared<StreamedBackend>(std::move(stream2));

    // Compose transformer list: index columns + receive_all for extras
    using BaseTs = TransformerList<Identity<arrow::Int32Type>, Identity<arrow::DoubleType>, Identity<arrow::BooleanType>, Identity<arrow::StringType>>;
    auto view = TableView<StreamedBackend, BaseTs, MetadataFilter<ProcessTrueKey, ProcessTrueVal>>(backend)
                    .addTransformer<ReceiveAllTransformer>();

    std::cout << "Rows via iterator with metadata filter after 2nd roundtrip:\n";
    for (auto row : view) {
        // get typed columns
        auto i = row.template get<0>();
        auto d = row.template get<1>();
        auto b = row.template get<2>();
        auto s = row.template get<3>();
        // receive_all extras
        auto extras = row.receive_all();
        std::cout << i << ", " << d << ", " << b << ", " << s;
        std::cout << ", extras=" << extras.size() << std::endl;
    }
    return 0;
}


import pyarrow as pa
import pyarrow.flight as flight
import threading

class EchoFlightServer(flight.FlightServerBase):
    def __init__(self, location):
        super().__init__(location)

    def do_put(self, context, descriptor, reader, writer):
        # Read incoming table
        table = reader.read_all()
        print("Server received table:", table.schema)
        # Echo it back under same descriptor
        writer.begin(table.schema, descriptor)
        # Stream by batches
        for batch in table.to_batches():
            writer.write_batch(batch)
        writer.done_writing()

    def do_get(self, context, ticket):
        # Tickets carry the descriptor
        descriptor = flight.FlightDescriptor.for_command(ticket.ticket)
        # For simplicity, reuse last put (not production safe)
        return flight.RecordBatchStream(self._last_table)

if __name__ == '__main__':
    server = EchoFlightServer(('localhost', 8815))
    print('Starting Flight relay on localhost:8815')
    threading.Thread(target=server.serve).start()

import pyarrow as pa
import pyarrow.flight as flight

# Construct a table with all primitive Arrow types
fields = [
    pa.field('i32', pa.int32()),
    pa.field('f64', pa.float64()),
    pa.field('bol', pa.bool_()),
    pa.field('str', pa.string()),
]
schema = pa.schema(fields)
columns = [
    pa.array([1, 2, 3]),
    pa.array([0.1, 0.2, 0.3]),
    pa.array([True, False, True]),
    pa.array(['a', 'b', 'c']),
]
table = pa.Table.from_arrays(columns, schema=schema)

def main():
    client = flight.FlightClient('grpc://localhost:8815')
    descriptor = flight.FlightDescriptor.for_command(b'my_table')

    # PUT: send table in batches of 2
    writer, _ = client.do_put(descriptor, schema)
    for batch in table.to_batches(2):
        writer.write_batch(batch)
    writer.close()

    # GET: retrieve back streaming row-wise
    info = client.get_flight_info(descriptor)
    reader = client.do_get(info.endpoints[0].ticket)

    print("Batch-wise streaming:")
    for batch in reader:
        print(batch)

    # Row-wise streaming
    print("Row-wise streaming:")
    for record in reader.read_table().to_batches(1):
        for row in record.to_pydict().values():
            print(row)

if __name__ == '__main__':
    main()
